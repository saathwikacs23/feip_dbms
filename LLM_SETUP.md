# ðŸ¤– LLM-Powered Natural Language Query Setup

## Overview
The system now supports **LLM-powered natural language to SQL conversion** using Groq's Qwen models for highly accurate query generation with full database schema context.

---

## Features

### With LLM (Groq API):
- âœ… **Highly accurate** query generation (95%+ confidence)
- âœ… **Full context awareness** of all tables, columns, and relationships
- âœ… **Complex query understanding** (multi-table joins, aggregations, filters)
- âœ… **Natural language flexibility** - understands various phrasings
- âœ… **Intelligent schema mapping** - knows which tables to use
- âœ… **Federated query support** across PostgreSQL, MongoDB, and CSV
- âœ… **Fast and FREE** - Groq provides free API access with generous limits
- âœ… **Streaming responses** - real-time query generation

### Without LLM (Fallback):
- âš¡ **Pattern matching** based on keywords (70% confidence)
- âš¡ **No API key required** - works offline
- âš¡ **Basic queries** supported
- âš¡ **Instant responses** - no network latency

---

## Setup Instructions

### Option 1: Use Groq API (Recommended)

#### Step 1: Get Groq API Key
1. Go to https://console.groq.com/keys
2. Sign up or log in (free account)
3. Click "Create API Key"
4. Copy your API key (starts with `gsk_...`)

#### Step 2: Configure the API Key

**Method A: Environment Variable (Recommended)**
```powershell
# Set for current session
$env:GROQ_API_KEY = "gsk_YOUR_KEY_HERE"

# Set permanently (Windows)
[System.Environment]::SetEnvironmentVariable('GROQ_API_KEY', 'gsk_YOUR_KEY_HERE', 'User')
```

**Method B: Config File**
1. Open `backend/config.py`
2. Find the line: `GROQ_API_KEY = os.getenv('GROQ_API_KEY', None)`
3. Replace with: `GROQ_API_KEY = 'gsk_YOUR_KEY_HERE'`

#### Step 3: Install Dependencies
```powershell
cd C:\Users\Lenovo\dbmsel\proj\backend
pip install groq==0.11.0
```

#### Step 4: Restart Flask Server
```powershell
python app.py
```

#### Step 5: Test
Open http://localhost:5000, go to Query page, and try:
- "Show me all regions with their climate data"
- "What is the average temperature by region?"
- "Find regions with high biodiversity and endangered species"

You should see `Method: llm` in the response info.

---

### Option 2: Use Without API Key (Pattern Matching)

No setup required! The system automatically falls back to pattern-based matching if no API key is configured.

Simply use the system as-is. You'll see `Method: pattern` in responses.

---

## Example Queries

### Simple Queries:
- "show all regions"
- "list climate data"
- "get biodiversity information"
- "display sensor readings"

### Analytical Queries:
- "what is the average temperature by region"
- "how many species are in each region"
- "which regions have the highest rainfall"
- "show total crop production by region"

### Complex Federated Queries:
- "show me regions with their climate and biodiversity data"
- "find regions with high CO2 levels and their temperatures"
- "list crop types, yields, and climate conditions by region"
- "which endangered species are in regions with high temperatures"

### Conditional Queries:
- "show regions where temperature is above 25 degrees"
- "find species in critically endangered status"
- "list crops with yield greater than 20 tons"
- "show sensors with high CO2 readings"

---

## Cost Information

### Groq API Pricing:
- **FREE** - Generous free tier with high rate limits
- **Qwen3-32B Model**: Fast and accurate, optimized for coding tasks
- **No credit card required** for free tier
- **Rate limits**: 30 requests/minute, 14,400 requests/day (free tier)

### Comparison:
- **OpenAI GPT-3.5**: $0.001-$0.003 per query (paid)
- **Groq Qwen3-32B**: FREE with generous limits
- **Pattern Matching**: FREE, unlimited, but less accurate

---

## How It Works

### With LLM:
1. User enters natural language question
2. System sends question + full database schema context to Groq Qwen
3. Qwen generates optimized SQL query using streaming
4. System executes query via Apache Drill
5. Results displayed with confidence score

### Schema Context Provided to LLM:
- All table/collection names and structures
- Column names, types, and descriptions
- Foreign key relationships
- Join patterns and best practices
- Example data and query syntax
- Common query patterns

---

## Troubleshooting

### "LLM not available" Message
**Cause**: No Groq API key configured
**Solution**: Set GROQ_API_KEY (see Step 2 above)

### "API Error" or Low Confidence
**Cause**: Invalid API key or network issues
**Solution**: 
1. Verify API key is correct
2. Check internet connection
3. Verify API key is active: https://console.groq.com/keys

### Queries Still Using Pattern Matching
**Cause**: API key not loaded
**Solution**: Restart Flask server after setting API key

### Rate Limiting
**Solution**: 
1. Free tier: 30 requests/minute, 14,400/day
2. Wait a minute if rate limited
3. Use pattern matching for burst queries

---

## Advanced Configuration

### Change Model:
Edit `backend/llm_query.py`, line ~220:
```python
model="qwen/qwen3-32b",  # Options: llama-3.3-70b-versatile, mixtral-8x7b-32768
```

### Adjust Confidence:
Edit `backend/llm_query.py`, line ~245:
```python
'confidence': 0.95,  # Adjust between 0.0 - 1.0
```

### Modify Temperature:
Edit `backend/llm_query.py`, line ~222:
```python
temperature=0.6,  # Lower = more deterministic, Higher = more creative (0.0-2.0)
```

### Adjust Token Limits:
Edit `backend/llm_query.py`:
```python
max_completion_tokens=4096,  # Max tokens in response
top_p=0.95,  # Nucleus sampling (0.0-1.0)
```

---

## Status Indicators

When using natural language queries, you'll see:

- **ðŸ¤– Method: llm** - Using Groq Qwen (high accuracy)
- **ðŸ”¤ Method: pattern** - Using pattern matching (fallback)
- **Confidence: 95%** - High confidence with LLM
- **Confidence: 70%** - Lower confidence with patterns

---

## Best Practices

1. **Be specific**: "Show regions with high temperature" is better than "show data"
2. **Use natural language**: Don't try to write SQL-like queries
3. **Ask for what you want**: "compare X and Y" instead of "join tables"
4. **Check confidence**: If <70%, rephrase the question
5. **Review generated SQL**: Learn from what the LLM generates

---

## Support

- Documentation: See README.md
- Database Schema: Review llm_query.py schema_context
- Test Queries: Use sample queries in the interface
- Pattern Fallback: Always available as backup

---

## Summary

âœ… **LLM-powered queries** provide the best accuracy and flexibility with FREE Groq API
âš¡ **Pattern matching** works offline without any setup
ðŸ”§ **Easy setup** - just get a free API key from console.groq.com
ðŸ’° **Cost-effective** - Groq provides generous free tier, no credit card needed
ðŸš€ **Fast streaming** - Real-time query generation with Qwen3-32B

Get started now: https://console.groq.com/keys
âœ… **Pattern matching** works without API key for basic queries
âœ… **Schema-aware** - LLM knows your entire database structure
âœ… **Cost-effective** - ~$0.001 per query with GPT-3.5
âœ… **Fallback ready** - automatically switches if LLM unavailable

**Get started**: Set your OPENAI_API_KEY and start asking questions in plain English! ðŸš€
